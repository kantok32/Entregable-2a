 ğŸ§  README: Multi-Model LLM Chatbot with Image Generation and Emotion Analysis
ğŸ“‹ DescripciÃ³n del Proyecto
Este proyecto es un Chatbot Multi-Modelo interactivo que utiliza modelos alojados en Hugging Face para:

Responder preguntas utilizando un modelo LLM (Language Learning Model).
Recordar el historial de conversaciÃ³n para proporcionar respuestas mÃ¡s coherentes.
Analizar emociones en los textos proporcionados por los usuarios.
Generar imÃ¡genes a partir de descripciones de texto utilizando un modelo ligero y eficiente.
El proyecto estÃ¡ construido con Gradio para proporcionar una interfaz grÃ¡fica interactiva y fÃ¡cil de usar.

ğŸ“¦ Requisitos Previos
Antes de ejecutar este proyecto, asegÃºrate de tener lo siguiente instalado en tu mÃ¡quina:

Python 3.8 o superior
Git
Dependencias del proyecto:
gradio
huggingface_hub
Instala las dependencias ejecutando:

bash
Copiar cÃ³digo
pip install -r requirements.txt
ğŸ” ConfiguraciÃ³n del Token de Hugging Face
Este proyecto utiliza modelos alojados en Hugging Face, por lo que necesitas un token de acceso para usarlos.

ğŸ“‹ CÃ³mo Obtener un Token de Acceso
Inicia sesiÃ³n en Hugging Face.
Genera un token de lectura.
Configura el token como variable de entorno en tu mÃ¡quina:
Linux/macOS:
bash
Copiar cÃ³digo
export HF_API_TOKEN="TU_TOKEN"
Windows (PowerShell):
powershell
Copiar cÃ³digo
$env:HF_API_TOKEN="TU_TOKEN"
ğŸš€ Instrucciones para Ejecutar el Proyecto
1ï¸âƒ£ Clona el Repositorio
bash
Copiar cÃ³digo
git clone https://huggingface.co/tu_usuario/tu_repositorio
cd tu_repositorio
2ï¸âƒ£ Instala las Dependencias
bash
Copiar cÃ³digo
pip install -r requirements.txt
3ï¸âƒ£ Ejecuta la AplicaciÃ³n
bash
Copiar cÃ³digo
python app.py
4ï¸âƒ£ Abre la Interfaz en tu Navegador
La aplicaciÃ³n estarÃ¡ disponible en http://127.0.0.1:7860.

ğŸ§© Diagrama de Flujo del Chatbot
El siguiente diagrama de flujo muestra cÃ³mo el chatbot selecciona el modelo adecuado y procesa la entrada del usuario:

mermaid
Copiar cÃ³digo
flowchart TD
    Start["Usuario ingresa una consulta"] --> SelectModel{Â¿Selecciona acciÃ³n?}
    SelectModel -- "CHATBOT" --> LLMResponse["Respuesta generada por el modelo LLM"]
    SelectModel -- "Generar Imagen" --> ImageResponse["GeneraciÃ³n de imagen en progreso"]
    SelectModel -- "AnÃ¡lisis de Emociones" --> EmotionResponse["AnÃ¡lisis de emociones en el texto"]
    LLMResponse --> End["Respuesta devuelta al usuario"]
    ImageResponse --> End
    EmotionResponse --> End

    Ejemplo de Uso
   En la carpeta assets se encuentran capturas de prueba de los 3 modelos utilizados

    
âš™ï¸ InstalaciÃ³n Opcional: Uso de un Entorno Virtual
Para mantener las dependencias aisladas y evitar conflictos, puedes crear un entorno virtual con los siguientes comandos:

Linux/macOS:
bash
Copiar cÃ³digo
python3 -m venv venv
source venv/bin/activate
Windows:
bash
Copiar cÃ³digo
python -m venv venv
.\venv\Scripts\activate
âœ… Modelos Utilizados
microsoft/Phi-3-mini-4k-instruct â€“ Modelo de lenguaje para responder preguntas y recordar el contexto de la conversaciÃ³n.
bhadresh-savani/distilbert-base-uncased-emotion â€“ Modelo para anÃ¡lisis de emociones.
stabilityai/stable-diffusion-2-1-base â€“ Modelo ligero para generaciÃ³n de imÃ¡genes.
ğŸ“„ Licencia
Este proyecto estÃ¡ bajo la licencia MIT. Puedes usarlo y modificarlo libremente bajo los tÃ©rminos de esta licencia.

