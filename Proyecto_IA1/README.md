
# Proyecto 1: Chatbot LLM con API de Hugging Face

## ğŸ“‹ DescripciÃ³n
Este proyecto es un chatbot interactivo que utiliza un modelo de lenguaje de Hugging Face para responder preguntas en tiempo real. La aplicaciÃ³n estÃ¡ construida con Gradio, lo que permite al usuario interactuar fÃ¡cilmente con el modelo a travÃ©s de una interfaz grÃ¡fica.

---

## ğŸ“¦ Requisitos
Antes de ejecutar este proyecto, asegÃºrate de tener lo siguiente instalado en tu equipo:
- **Python 3.8 o superior**
- **Gradio**
- **huggingface_hub**

Instala las dependencias ejecutando:
```bash
pip install gradio huggingface_hub
```

---

## ğŸ” ConfiguraciÃ³n del Token de Hugging Face
El proyecto requiere un **token de acceso** de Hugging Face para conectarse a la API del modelo.

### CÃ³mo Obtener un Token
1. Inicia sesiÃ³n en tu cuenta de Hugging Face:  
   ğŸ‘‰ [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
2. Crea un nuevo token con los siguientes permisos habilitados:
   - **`Read`** (lectura)
3. Copia el token generado.

### Configura el Token como Variable de Entorno
Para mantener tu token seguro, configÃºralo como una variable de entorno en tu sistema:

- **Windows (PowerShell):**
   ```powershell
   $env:HF_API_TOKEN="TU_TOKEN"
   ```

- **Linux/macOS:**
   ```bash
   export HF_API_TOKEN="TU_TOKEN"
   ```

---

## ğŸš€ CÃ³mo Ejecutar el Archivo
1. Guarda el cÃ³digo en un archivo llamado **`app.py`**.
2. Abre la terminal en la carpeta donde guardaste el archivo.
3. Ejecuta el archivo con el siguiente comando:

```bash
python app.py
```

4. Abre el navegador y visita la URL proporcionada (por defecto: `http://127.0.0.1:7860`).

---

## ğŸ“š Modelo Usado
- **Modelo:** `microsoft/Phi-3-mini-4k-instruct`
- **Fuente:** Hugging Face

El modelo estÃ¡ diseÃ±ado para responder preguntas en lenguaje natural.

---

## ğŸ“¤ ParÃ¡metros en la PeticiÃ³n
La aplicaciÃ³n realiza peticiones a la API de Hugging Face utilizando los siguientes parÃ¡metros:
- **`messages`**: Lista de mensajes en formato JSON. Ejemplo:
  ```json
  [
    {"role": "user", "content": "Â¿CuÃ¡l es la capital de Francia?"}
  ]
  ```
- **`max_tokens`**: NÃºmero mÃ¡ximo de tokens en la respuesta (500).

---

## âœ¨ Ejemplo de Uso
1. Ingresa una pregunta en el cuadro de texto, por ejemplo:
   ```text
   Â¿CuÃ¡l es la capital de Francia?
   ```
2. Presiona el botÃ³n **"Enviar"**.
3. La respuesta generada serÃ¡:
   ```text
   La capital de Francia es ParÃ­s.
   ```

---

## âš™ï¸ InstalaciÃ³n Opcional (Entorno Virtual)
Para mantener las dependencias aisladas, puedes crear un entorno virtual:
```bash
python -m venv venv
source venv/bin/activate  # En Linux/macOS
.env\Scriptsctivate  # En Windows
```

---

## ğŸ“„ Licencia
Este proyecto estÃ¡ bajo la licencia MIT.

